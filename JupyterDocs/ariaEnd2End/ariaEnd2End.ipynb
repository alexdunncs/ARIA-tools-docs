{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for settine up time-series processing\n",
    "\n",
    "**Author**: David Bekaert - Jet Propulsion Laboratory\n",
    "\n",
    "This notebook provides an example on how one could set up a processing stack and run it through MintPy procesisng. For detailed information on aria-tools one should look into the seperate ariaDownload, ariaExtract, ariaTSprep, and MintPy notebooks seperately.\n",
    "\n",
    "\n",
    "In this notebook, we give an example on how to process the main island of Hawaii uisng ARIA Geocoded UNWrapped interferogram (GUNW) products using on few user-defined parameters. \n",
    "\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "Both the initial setup (<b>Prep A</b> section) and download of the data (<b>Prep B</b> section) should be run at the start of the notebook. All other sections (examples and applications) do not need to be run in order.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Potential Errors:</b> \n",
    "    \n",
    "- GDAL uses \"HDF5\" driver instead of \"netCDF/Network Common Data Format\" on GUNW products. Verify GDAL version >= 3.\n",
    "- ARIA-tools and MintPy needs to be installed to run this notebook.\n",
    "- Virtual data access requires additional pre-requisites as liste on the ARIA-tools website.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "<a id='example_TOC'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**1. Verifiy if pre-requisites are installed**](#prereq)\n",
    "\n",
    "[**2. User configurable inputs**](#inputs)\n",
    "\n",
    "[**3. Download of products - ariaDownload.py**](#download)\n",
    "\n",
    "[**4. Minimum overlap computation**](#overlap)\n",
    "\n",
    "[**5. Time-series preparation - ariaTSprep.py**](#tsprep)\n",
    "\n",
    "[**6. Time-series processing - MintPy**](#mintpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Verifiy if pre-requisites are installed\n",
    "<a id='prereq'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we verify if aria-tools and mintpy are installed on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "tutorial_home_dir = os.path.abspath(os.getcwd())\n",
    "print(\"Tutorial directory: \", tutorial_home_dir)\n",
    "\n",
    "\n",
    "# Verifying if ARIA-tools is installed correctly\n",
    "try:\n",
    "    import ARIAtools.shapefile_util as shputil\n",
    "except:\n",
    "    raise Exception('ARIA-tools is missing from your PYTHONPATH')\n",
    " \n",
    "# Verifying if Mintpy is installed correctly\n",
    "# verify if mintpy install is complete:\n",
    "try:\n",
    "    import numpy as np\n",
    "    from mintpy import view, tsview, plot_network, plot_transection, plot_coherence_matrix\n",
    "except:\n",
    "    print(\"Looks like mintPy is not fully installed\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. User configurable inputs\n",
    "<a id='inputs'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, are a minum of configurable parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Workdirectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The working directory in which the outputs are organized in separate subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Bounding Box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user can specify a rectangular bounding box (South-North-West-East coordinates) ` 'S N W E'` or can provide a more complex area of interest using a shapefile or geoJSON as ` path_to_file.shp`. A schematic example is shown in **Fig 1** for both scenarios.\n",
    "\n",
    "<img src=\"./support_docs/crop.png\" alt=\"cropping\" width=\"700\">\n",
    "<blockquote><center><b> Fig. 1 </b> Schematic examples of the user-specified area of interest. </center></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we include two scenario's for a use to pick from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_SNWE = \"18.8 20.3 -156.1 -154.8\"\n",
    "bbox_shp = os.path.join(tutorial_home_dir, 'support_docs', 'Big_Island', 'Big_Island.shp')\n",
    "\n",
    "# Set the bbox to be used in subsequent processing:\n",
    "bbox = bbox_SNWE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 S1 track number "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentinel-1 track number (string) for which the data will be downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracknumber = '124'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Start and end time of Sentinel-1 period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start and end time of the Sentinel-1 record provided in YYYYMMDD string format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '20181215'\n",
    "end = '20190101'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Download format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your machine support virtual data access, see [here](https://github.com/aria-tools/ARIA-tools#aria-tools-with-support-for-s3-virtual-data-access) for the requirements, one can opt to avoid data-download from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True/False for using virtual data download\n",
    "virtualDownload = False\n",
    "\n",
    "\n",
    "# no changes needed below\n",
    "# Selecting the download option to be used in subsequent processing.\n",
    "if virtualDownload:\n",
    "    download = 'url'\n",
    "    downloadDir = os.path.join(work_dir,'URLproducts')\n",
    "else:\n",
    "    download = 'download'\n",
    "    downloadDir = os.path.join(work_dir,'products')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Summary of user inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Work directory: \", work_dir)\n",
    "print(\"Download: \", download)\n",
    "print(\"Start: \", start)\n",
    "print(\"End: \", end)\n",
    "print(\"Track: \", tracknumber)\n",
    "print(\"bbox: \", bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download of products\n",
    "<a id='download'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will use ariaDownload to download the products. Netcdf products will be downloaded unless the virtual data option was selected, which downloads a list of product URL locations in S3.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ariaDownload.py -t {tracknumber} -w {downloadDir} -b \"{bbox}\" -s {start} -e {end} -o {download}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Minimum overlap computation\n",
    "<a id='overlap'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum area threshold can be used to reject those inteferferograms for which the intersection with the bounding box does not meet a minimum area overlap as set by the user. As long as the user study-area is within one of the ARIA production AOI's, there should always be a temporally conencted network, although partial intererograms can exist when the user study-area covers multiple ARIA production AOI's.\n",
    "\n",
    "We will enforce that interferograms needs to compeltely cover the study area of the user. To do so we will calculate what this area will be in advsance and then specify it as a threshold in subsequent processing. \n",
    "\n",
    "We will apply the following steps:\n",
    "- We will estiamte the ground swath by using historic SLC data for the given track and bounding box. We will leverage for this the DAAC api to retreive SLC granule bounding boxes and take the union of these as indicator for the ground track.\n",
    "- We will intersect the user boundingbox with this ground track to compute and calculate its area to estiamte the  spatial coverage of Sentinel-1 within the users study area.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the S1 ground swath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will qeuerry the DAAC api for historic data and retrieve a CSV file with meta-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Caling the DAAC API and retrieving the SLCs outlines\n",
    "# checking if bbox exist\n",
    "from ARIAtools.shapefile_util import open_shapefile\n",
    "if os.path.exists(os.path.abspath(bbox)):\n",
    "    bounds = open_shapefile(bbox, 0, 0).bounds\n",
    "    W,S,E,N = [str(i) for i in bounds]\n",
    "else:\n",
    "    try:\n",
    "        S, N, W, E = bbox.split()\n",
    "    except:\n",
    "        raise Exception('Cannot understand the --bbox argument. Input string was entered incorrectly or path does not exist.')\n",
    "\n",
    "url_base    = 'https://api.daac.asf.alaska.edu/services/search/param?'\n",
    "url = '{}platform=SENTINEL-1&processinglevel=SLC&beamSwath=IW&output=CSV&maxResults=5000000'.format(url_base)\n",
    "url += '&relativeOrbit={}'.format(tracknumber)\n",
    "url += '&bbox=' + ','.join([W,S,E,N])\n",
    "\n",
    "# could also include start and end time for period. Needs to be of the form:\n",
    "#start=2018-12-15T00:00:00.000Z&end=2019-01-01T23:00:00.000Z\n",
    "\n",
    "url = url.replace(' ', '+')\n",
    "print (url)\n",
    "\n",
    "!wget -O test.csv \"{url}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will load the meta-data and merge all the SLC granules to estimate the ground swath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ARIAtools.shapefile_util import shapefile_area\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def polygonFromFrame(frame):\n",
    "    '''\n",
    "        Create a Shapely polygon from the coordinates of a frame.\n",
    "    '''\n",
    "    P=Polygon([(float(frame['Near Start Lon']),float(frame['Near Start Lat'])),\n",
    "                (float(frame['Far Start Lon']),float(frame['Far Start Lat'])),\n",
    "                (float(frame['Far End Lon']),float(frame['Far End Lat'])),\n",
    "                (float(frame['Near End Lon']),float(frame['Near End Lat']))])\n",
    "    return P\n",
    "\n",
    "track_metadata=pd.read_csv('test.csv',index_col=False)\n",
    "\n",
    "# Compute polygons\n",
    "SLCPolygons=[]\n",
    "for frameNdx,frame in track_metadata.iterrows():\n",
    "    # Convert frame coords to polygon\n",
    "    SLCPolygons.append(polygonFromFrame(frame))\n",
    "\n",
    "# Find union of polygons\n",
    "swathPolygon=SLCPolygons[0]\n",
    "for SLCPolygon in SLCPolygons:\n",
    "    swathPolygon=swathPolygon.union(SLCPolygon)\n",
    "print(swathPolygon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the minimum overlap by intersection of the ground track and user boundingbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert the bbox in a shapefile (SNWG option)\n",
    "bboxCoord = [float(i) for i in bbox.split(' ')]\n",
    "bboxPolygon = Polygon(([bboxCoord[2],bboxCoord[1]],[bboxCoord[3],bboxCoord[1]],[bboxCoord[3],bboxCoord[0]],[bboxCoord[2],bboxCoord[0]]))\n",
    "\n",
    "# Load the shapefile (shapefile option)\n",
    "# bboxRead = json.loads(open('./user_bbox.json').read())\n",
    "# bboxPolygon = Polygon(bboxRead['features'][0]['geometry']['coordinates'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use shapely intersect function.\n",
    "bboxSwathPolygon=bboxPolygon.intersection(swathPolygon)\n",
    "\n",
    "# TODO calculate shapely area.\n",
    "minOverlap = shapefile_area(bboxSwathPolygon)\n",
    "print(\"Common intersection has an area of %fkm\\u00b2\"%(minOverlap))\n",
    "\n",
    "# TODO for numerical issue, should make this area threshold a little bit smaller. i.e. 90% or so\n",
    "minOverlap = minOverlap*0.9\n",
    "print(\"Minimum Area threshold set to 90%\" + \" or %fkm\\u00b2\"%(minOverlap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Time-series preparation\n",
    "<a id='tsprep'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will use ariaTSprep to prepapre for time-series processing. This includes the stitching of individual products, and extraction of the inputs expected by MintPy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ariaTSsetup.py -f \"{downloadDir}/*\" -b \"{bbox}\" --mask Download --dem Download -mo {minOverlap}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three VRT files *cohStack.vrt*, *connCompStack.vrt*, *unwrapStack.vrt* have been generated under the *stack* subdirectory of your specified work directory. They point to your extracted coherence, connected component, and unwrapped phase files, respectively. The relevant meta-data is directly embedded within these vrt stacks. Note that these VRT stack files are virtual files pointing to individual interferograms in the *unwrappedPhase* and *coherence* directories. In addition, a DEM file (*SRTM_3arcsec.dem*) and water mask (*watermask.msk*) have been downloaded in respectively the *dem* and *mask* folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls stack/*\n",
    "!ls dem/SRTM_3arcsec.dem\n",
    "!ls mask/watermask.msk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time-series processing \n",
    "<a id='mintpy'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!smallbaselineApp.py -g smallbaselineApp.cfg --dostep load_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
